<ssd0>
sudo NV_GPU=0 nvidia-docker run --name TFSSD0 -it -d --net=host \
 -v "/drv3/tf_ssd/share:/ssd_ws" \
 tensorflow/tensorflow:1.14.0-gpu-py3

sudo docker exec -it TFSSD0 /bin/bash
sudo docker restart TFSSD0

----------------------------------------------------
2-0 install package
$ pip install lxml
$ pip install pillow
$ pip install Cython
$ apt-get update
$ apt-get install python3-tk
$ pip install --user contextlib2
$ apt-get install git vim 
==========================================================================================================================================================================
2-1 Train용
$ cd /ssd_ws
cd tod0

$ git clone https://github.com/tensorflow/models.git
$ mv models train_models
$ cd train_models

git checkout 5ed215b2ae0fd9650d1650953afcffdd23bb28f6

2-3 pycocotools, protocbuf 설치
-----pycocotools 설치-----
$ cd /ssd_ws/tod0/train_models/research

$ export PYTHONPATH=$PYTHONPATH:/ssd_ws/tod0/train_models/research:/ssd_ws/tod0/train_models/research/slim

$ git clone https://github.com/cocodataset/cocoapi.git
$ cd cocoapi/PythonAPI
$ make
$ cp -r pycocotools /ssd_ws/tod0/train_models/research/
-------------------------

-----protocbuf 설치-------
$ cd /ssd_ws/tod0/train_models/research
-
$ curl -OL https://github.com/google/protobuf/releases/download/v3.2.0/protoc-3.2.0-linux-x86_64.zip
$ unzip protoc-3.2.0-linux-x86_64.zip -d protoc3
$ mv protoc3/bin/* /usr/local/bin/
$ mv protoc3/include/* /usr/local/include/
$ protoc object_detection/protos/*.proto --python_out=.
$ python object_detection/builders/model_builder_test.py

OK가 뜨면 성공
----------------------
----------------------

3-3 train model modify

$ vim /ssd_ws/tod0/train_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config

**************************************************
line: 151, 152 
해당 라인은 transfer learning을 하거나 fine_tuning할 때 사용하므로 현재는 사용하지 않는다.
**************************************************
**만약 transfer 러닝을 하려면 이렇게
** model.ckpt 다음 숫자는 실제로 pretrained 된 체크포인트 파일 이름을 따른다.

  fine_tune_checkpoint: "/ssd_ws/dataset/pretrained/model.ckpt-6919"
  from_detection_checkpoint: true
**************************************************

line: 170,184 -> path설정
해당 라인에 적혀있는 path의 tfrecord를 train하므로 우리데이터셋 경로로 바꿔주자.
170, 184: /ssd_ws/dataset/cocodata/tfrecords/ 여기에 ms만 지우면됨

line: 172,186 -> mscoco_label_map.pbtxt 경로를 설정해줘야 한다. 
172, 186: /ssd_ws/tod0/train_models/research/object_detection/data/mscoco_label_map.pbtxt

3-4 train
이제 학습에 필요한 파라미터들을 설정해주고 실행하면 된다.
mkdir /ssd_ws/classex/opt00/save_models/ 

$ PIPELINE_CONFIG_PATH='/ssd_ws/tod0/train_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config'
$ MODEL_DIR='/ssd_ws/classex/opt00/save_models/'

**************************************
$ NUM_TRAIN_STEPS=10000
**************************************************
**만약 transfer 러닝을 하려면
$ NUM_TRAIN_STEPS=1000
******************************************

$ NUM_EVAL_STEPS=100
$ SAMPLE_1_OF_N_EVAL_EXAMPLES=1
------------------------------
터미널을 빠져나가면 안될 듯

$ python object_detection/model_main.py \
--pipeline_config_path=${PIPELINE_CONFIG_PATH} \
--model_dir=${MODEL_DIR} \
--num_train_steps=${NUM_TRAIN_STEPS} \
--num_eval_steps=${NUM_EVAL_STEPS} \
--checkpoint_dir=${PRE_TRAIN} \
--sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
--num_clones=1 \
--ps_tasks=1

************************************************
***** EXPRESS upper statement as 1 line. *****
************************************************
python object_detection/model_main.py --pipeline_config_path=${PIPELINE_CONFIG_PATH} --model_dir=${MODEL_DIR} --num_train_steps=${NUM_TRAIN_STEPS} --num_eval_steps=${NUM_EVAL_STEPS} --checkpoint_dir=${PRE_TRAIN} --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES --num_clones=1 --ps_tasks=1
*************************************************

==============================================================================================
=================================
============================================================================================

<<4 Export pb>>

* MANDATORY !!!!
exit

sudo docker restart TFSSD0
sudo docker exec -it TFSSD0 /bin/bash

===========================================
4-1 Export용 model

$ cd /ssd_ws/tod0/

$ git clone https://github.com/tensorflow/models.git
$ mv models export_models
$ cd export_models
$ git checkout ae0a9409212d0072938fa60c9f85740bb89ced7e

*다른 브랜치 성공 확인*
.../export_models/research# ls
.../export_models/research# ls ../../train_models/research/
===================

4-2 Export용 model 환경 확인

$ cd /ssd_ws/tod0/export_models/research
$ export PYTHONPATH=$PYTHONPATH:/ssd_ws/tod0/export_models/research:/ssd_ws/tod0/export_models/research/slim

$ protoc object_detection/protos/*.proto --python_out=.
$ python object_detection/builders/model_builder_test.py
--> ok 확인

======================
4-3 Export용 model 설정

cp /ssd_ws/tod0/train_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config ./object_detection/samples/configs/
$ vim ./object_detection/samples/configs/ssd_inception_v2_coco.config
line 101: override 부분 주석

$ INPUT_TYPE=image_tensor

-----------------------------
$ PIPELINE_CONFIG_PATH='/ssd_ws/tod0/export_models/research/object_detection/samples/configs/ssd_inception_v2_coco.config'
ls /ssd_ws/classex/opt00/save_models/

**************************************************
$ TRAINED_CKPT_PREFIX='/ssd_ws/classex/opt00/save_models/coco_test/model.ckpt-10000'

**************************************************
**만약 transfer 러닝을 하였다면 이렇게. -> 사실 그냥 가장 큰 숫자의 ckpt 를 사용하면 된다.

$ TRAINED_CKPT_PREFIX='/ssd_ws/tod0/save_models/coco_test/model.ckpt-5000'
**************************************************

mkdir /ssd_ws/classex/opt00/pbfiles

$ EXPORT_DIR='/ssd_ws/classex/opt00/pbfiles'

================================
4-4 Export pb

$ python object_detection/export_inference_graph.py \
--input_type=${INPUT_TYPE} \
--pipeline_config_path=${PIPELINE_CONFIG_PATH} \
--trained_checkpoint_prefix=${TRAINED_CKPT_PREFIX} \
--output_directory=${EXPORT_DIR}

==================================================
************************************************
***** EXPRESS upper statement as 1 line. *****
************************************************
python object_detection/export_inference_graph.py --input_type=${INPUT_TYPE} --pipeline_config_path=${PIPELINE_CONFIG_PATH} --trained_checkpoint_prefix=${TRAINED_CKPT_PREFIX} --output_directory=${EXPORT_DIR}
************************************************
